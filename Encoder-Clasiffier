{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPrJjdDshlQTxj1SuHwgeu/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MCC-Oscar-Urias/ducksstrategy/blob/master/Encoder-Clasiffier\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI4bmClv0Wi7"
      },
      "source": [
        "import keras\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import gzip\r\n",
        "\r\n",
        "from keras.models import Model\r\n",
        "from keras.optimizers import RMSprop\r\n",
        "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.models import Model,Sequential\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\r\n",
        "from keras import regularizers\r\n",
        "from keras import backend as K\r\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "pLqO23_X0imu",
        "outputId": "32d5560f-9099-47f2-aa04-b050052ebd57"
      },
      "source": [
        "def extract_data(filename, num_images):\r\n",
        "    with gzip.open(filename) as bytestream:\r\n",
        "        bytestream.read(16)\r\n",
        "        buf = bytestream.read(28 * 28 * num_images)\r\n",
        "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\r\n",
        "        data = data.reshape(num_images, 28,28)\r\n",
        "        return data\r\n",
        "train_data = extract_data('train-images-idx3-ubyte.gz', 60000)\r\n",
        "test_data = extract_data('t10k-images-idx3-ubyte.gz', 10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-546e44cc465b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train-images-idx3-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't10k-images-idx3-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-546e44cc465b>\u001b[0m in \u001b[0;36mextract_data\u001b[0;34m(filename, num_images)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbytestream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mbytestream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytestream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m28\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train-images-idx3-ubyte.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "zEFxWGOl0mlu",
        "outputId": "c99e5934-3f3d-4ba3-a99e-295f853ded99"
      },
      "source": [
        "def extract_labels(filename, num_images):\r\n",
        "    with gzip.open(filename) as bytestream:\r\n",
        "        bytestream.read(8)\r\n",
        "        buf = bytestream.read(1 * num_images)\r\n",
        "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\r\n",
        "        return labels\r\n",
        "train_labels = extract_labels('train-labels-idx1-ubyte.gz',60000)\r\n",
        "test_labels = extract_labels('t10k-labels-idx1-ubyte.gz',10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-737e534fd888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train-labels-idx1-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't10k-labels-idx1-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-737e534fd888>\u001b[0m in \u001b[0;36mextract_labels\u001b[0;34m(filename, num_images)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbytestream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mbytestream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytestream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train-labels-idx1-ubyte.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEi7vhiY0qgE"
      },
      "source": [
        "\r\n",
        "# Shapes of training set\r\n",
        "print(\"Training set (images) shape: {shape}\".format(shape=train_data.shape))\r\n",
        "\r\n",
        "# Shapes of test set\r\n",
        "print(\"Test set (images) shape: {shape}\".format(shape=test_data.shape))\r\n",
        "\r\n",
        "\r\n",
        "# Create dictionary of target classes\r\n",
        "label_dict = {\r\n",
        " 0: 'A',\r\n",
        " 1: 'B',\r\n",
        " 2: 'C',\r\n",
        " 3: 'D',\r\n",
        " 4: 'E',\r\n",
        " 5: 'F',\r\n",
        " 6: 'G',\r\n",
        " 7: 'H',\r\n",
        " 8: 'I',\r\n",
        " 9: 'J',\r\n",
        "}\r\n",
        "\r\n",
        "plt.figure(figsize=[5,5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwQSEx6G0ura"
      },
      "source": [
        "# Display the first image in training data\r\n",
        "plt.subplot(121)\r\n",
        "curr_img = np.reshape(train_data[10], (28,28))\r\n",
        "curr_lbl = train_labels[10]\r\n",
        "plt.imshow(curr_img, cmap='gray')\r\n",
        "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\r\n",
        "\r\n",
        "# Display the first image in testing data\r\n",
        "plt.subplot(122)\r\n",
        "curr_img = np.reshape(test_data[10], (28,28))\r\n",
        "curr_lbl = test_labels[10]\r\n",
        "plt.imshow(curr_img, cmap='gray')\r\n",
        "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "train_data = train_data.reshape(-1, 28,28, 1)\r\n",
        "test_data = test_data.reshape(-1, 28,28, 1)\r\n",
        "train_data.shape, test_data.shape\r\n",
        "\r\n",
        "((60000, 28, 28, 1), (10000, 28, 28, 1))\r\n",
        "\r\n",
        "train_data.dtype, test_data.dtype\r\n",
        "\r\n",
        "\r\n",
        "np.max(train_data), np.max(test_data)\r\n",
        "\r\n",
        "(255.0, 255.0)\r\n",
        "\r\n",
        "train_data = train_data / np.max(train_data)\r\n",
        "test_data = test_data / np.max(test_data)\r\n",
        "np.max(train_data), np.max(test_data)\r\n",
        "\r\n",
        "(1.0, 1.0)\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,\r\n",
        "                                                             train_data,\r\n",
        "                                                             test_size=0.2,\r\n",
        "                                                             random_state=13)\r\n",
        "\r\n",
        "batch_size = 64\r\n",
        "epochs = 50\r\n",
        "inChannel = 1\r\n",
        "x, y = 28, 28\r\n",
        "input_img = Input(shape = (x, y, inChannel))\r\n",
        "num_classes = 10\r\n",
        "\r\n",
        "def encoder(input_img):\r\n",
        "    #encoder\r\n",
        "    #input = 28 x 28 x 1 (wide and thin)\r\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\r\n",
        "    conv1 = BatchNormalization()(conv1)\r\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\r\n",
        "    conv1 = BatchNormalization()(conv1)\r\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\r\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\r\n",
        "    conv2 = BatchNormalization()(conv2)\r\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\r\n",
        "    conv2 = BatchNormalization()(conv2)\r\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\r\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\r\n",
        "    conv3 = BatchNormalization()(conv3)\r\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\r\n",
        "    conv3 = BatchNormalization()(conv3)\r\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\r\n",
        "    conv4 = BatchNormalization()(conv4)\r\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\r\n",
        "    conv4 = BatchNormalization()(conv4)\r\n",
        "    return conv4\r\n",
        "\r\n",
        "def decoder(conv4):    \r\n",
        "    #decoder\r\n",
        "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4) #7 x 7 x 128\r\n",
        "    conv5 = BatchNormalization()(conv5)\r\n",
        "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\r\n",
        "    conv5 = BatchNormalization()(conv5)\r\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5) #7 x 7 x 64\r\n",
        "    conv6 = BatchNormalization()(conv6)\r\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\r\n",
        "    conv6 = BatchNormalization()(conv6)\r\n",
        "    up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\r\n",
        "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 32\r\n",
        "    conv7 = BatchNormalization()(conv7)\r\n",
        "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\r\n",
        "    conv7 = BatchNormalization()(conv7)\r\n",
        "    up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\r\n",
        "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\r\n",
        "    return decoded\r\n",
        "\r\n",
        "autoencoder = Model(input_img, decoder(encoder(input_img)))\r\n",
        "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())\r\n",
        "\r\n",
        "autoencoder.summary()\r\n",
        "\r\n",
        "\r\n",
        "autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))\r\n",
        "\r\n",
        "loss = autoencoder_train.history['loss']\r\n",
        "val_loss = autoencoder_train.history['val_loss']\r\n",
        "epochs = range(50)\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\r\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n",
        "\r\n",
        "autoencoder.save_weights('autoencoder.h5')\r\n",
        "\r\n",
        "# Change the labels from categorical to one-hot encoding\r\n",
        "train_Y_one_hot = to_categorical(train_labels)\r\n",
        "test_Y_one_hot = to_categorical(test_labels)\r\n",
        "\r\n",
        "# Display the change for category label using one-hot encoding\r\n",
        "print('Original label:', train_labels[0])\r\n",
        "print('After conversion to one-hot:', train_Y_one_hot[0])\r\n",
        "\r\n",
        "\r\n",
        "train_X,valid_X,train_label,valid_label = train_test_split(train_data,train_Y_one_hot,test_size=0.2,random_state=13)\r\n",
        "\r\n",
        "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape\r\n",
        "\r\n",
        "((48000, 28, 28, 1), (12000, 28, 28, 1), (48000, 10), (12000, 10))\r\n",
        "\r\n",
        "def encoder(input_img):\r\n",
        "    #encoder\r\n",
        "    #input = 28 x 28 x 1 (wide and thin)\r\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\r\n",
        "    conv1 = BatchNormalization()(conv1)\r\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\r\n",
        "    conv1 = BatchNormalization()(conv1)\r\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\r\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\r\n",
        "    conv2 = BatchNormalization()(conv2)\r\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\r\n",
        "    conv2 = BatchNormalization()(conv2)\r\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\r\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\r\n",
        "    conv3 = BatchNormalization()(conv3)\r\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\r\n",
        "    conv3 = BatchNormalization()(conv3)\r\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\r\n",
        "    conv4 = BatchNormalization()(conv4)\r\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\r\n",
        "    conv4 = BatchNormalization()(conv4)\r\n",
        "    return conv4\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def fc(enco):\r\n",
        "    flat = Flatten()(enco)\r\n",
        "    den = Dense(128, activation='relu')(flat)\r\n",
        "    out = Dense(num_classes, activation='softmax')(den)\r\n",
        "    return out\r\n",
        "\r\n",
        "encode = encoder(input_img)\r\n",
        "full_model = Model(input_img,fc(encode))\r\n",
        "\r\n",
        "for l1,l2 in zip(full_model.layers[:19],autoencoder.layers[0:19]):\r\n",
        "    l1.set_weights(l2.get_weights())\r\n",
        "    \r\n",
        "autoencoder.get_weights()[0][1]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "full_model.get_weights()[0][1]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "for layer in full_model.layers[0:19]:\r\n",
        "    layer.trainable = False\r\n",
        "    \r\n",
        "full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\r\n",
        "\r\n",
        "full_model.summary()\r\n",
        "\r\n",
        "classify_train = full_model.fit(train_X, train_label, batch_size=64,epochs=100,verbose=1,validation_data=(valid_X, valid_label))\r\n",
        "\r\n",
        "full_model.save_weights('autoencoder_classification.h5')\r\n",
        "\r\n",
        "for layer in full_model.layers[0:19]:\r\n",
        "    layer.trainable = True\r\n",
        "    \r\n",
        "full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\r\n",
        "full_model.save_weights('classification_complete.h5')\r\n",
        "\r\n",
        "accuracy = classify_train.history['acc']\r\n",
        "val_accuracy = classify_train.history['val_acc']\r\n",
        "loss = classify_train.history['loss']\r\n",
        "val_loss = classify_train.history['val_loss']\r\n",
        "epochs = range(len(accuracy))\r\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\r\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\r\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n",
        "test_eval = full_model.evaluate(test_data, test_Y_one_hot, verbose=0)\r\n",
        "\r\n",
        "print('Test loss:', test_eval[0])\r\n",
        "print('Test accuracy:', test_eval[1])\r\n",
        "predicted_classes = full_model.predict(test_data)\r\n",
        "\r\n",
        "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\r\n",
        "predicted_classes.shape, test_labels.shape\r\n",
        "\r\n",
        "correct = np.where(predicted_classes==test_labels)[0]\r\n",
        "print (\"Found %d correct labels\" % len(correct))\r\n",
        "for i, correct in enumerate(correct[:9]):\r\n",
        "    plt.subplot(3,3,i+1)\r\n",
        "    plt.imshow(test_data[correct].reshape(28,28), cmap='gray', interpolation='none')\r\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], test_labels[correct]))\r\n",
        "    plt.tight_layout()\r\n",
        "    \r\n",
        "incorrect = np.where(predicted_classes!=test_labels)[0]\r\n",
        "print (\"Found %d incorrect labels\" % len(incorrect))\r\n",
        "for i, incorrect in enumerate(incorrect[:9]):\r\n",
        "    plt.subplot(3,3,i+1)\r\n",
        "    plt.imshow(test_data[incorrect].reshape(28,28), cmap='gray', interpolation='none')\r\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], test_labels[incorrect]))\r\n",
        "    plt.tight_layout()\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\r\n",
        "print(classification_report(test_labels, predicted_classes, target_names=target_names))    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}